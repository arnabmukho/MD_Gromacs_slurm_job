#!/bin/bash
#
#SBATCH --partition=braf         ### Partition (you may need to change this)
#SBATCH --job-name=gromacs_on_2_nodes
#SBATCH --time=3-00:00:00       ### WallTime - set it accordningly

#SBATCH --nodes           1    # May vary
#SBATCH --ntasks-per-core 32    # Bind one MPI tasks to one CPU core
#SBATCH --ntasks-per-node 32  # Must be less/equal to the number of CPU cores
#SBATCH --cpus-per-task   1    # Must be 2, unless you have a better guess
#SBATCH --gres=gpu:2    # Must be 2, unless you have a better guess

#SBATCH -o slurm.%j.out        # STDOUT
#SBATCH -e slurm.%j.err        # STDERR

module purge
module load  apps/gromacs/2020.3/mpich+gcc_10.2.0/gpu

export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}
export OMP_PLACES=cores
export OMP_PROC_BIND=spread
export UCX_NET_DEVICES=mlx5_0:1

cd $SLURM_SUBMIT_DIR

mpirun gmx_mpi grompp -f step4.0_minimization.mdp -c step3_input.gro -r step3_input.gro -p topol.top -o em.tpr ; gmx_mpi mdrun -deffnm em ; gmx_mpi grompp -f  step4.1_equilibration.mdp -c em.gro -r em.gro -p topol.top -o nvt.tpr -n index.ndx ; gmx_mpi mdrun -deffnm nvt ; gmx_mpi grompp -f npt.mdp -c nvt.gro -r nvt.gro -t nvt.cpt -p topol.top -o npt.tpr -n index.ndx ; gmx_mpi mdrun -deffnm npt ; gmx_mpi grompp -f step5_production.mdp -c npt.gro -t npt.cpt -p topol.top -o md_new.tpr -n index.ndx ; gmx_mpi mdrun -deffnm md_new
